{SQUARED_OUTPUT=}ran this yesFinished run at {current_time} {SQUARED_OUTPUT=}

--------
Finished run at 20231110-220433 SQUARED_OUTPUT=True

--------
Finished run at 20231110-220509 SQUARED_OUTPUT=True

--------
Finished run at 20231110-22:05:28 SQUARED_OUTPUT=True

--------
Finished run at 20231110-22:06:26
SQUARED_OUTPUT=True
NUM_EPOCHS=5000
NUM_TUBES=4

--------
Finished run at 20231110-23:30:13
SQUARED_OUTPUT=True  NUM_EPOCHS=5000
average_loss_end=4.393092235096796
final LEARNING_RATE=1.0000000000000002e-06  NUM_TUBES=4 NUM_COLORS=2  

--------
Finished run at 20231110-23:32:27
SQUARED_OUTPUT=True  NUM_EPOCHS=5000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=3.89901919105774

--------
Finished run at 20231111-00:01:08
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=5.8331042491516884e-05 



--------
Finished run at 20231111-00:17:25
SQUARED_OUTPUT=True  NUM_EPOCHS=15000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=3.201140181577681 



--------
Finished run at 20231111-00:17:48
SQUARED_OUTPUT=True  NUM_EPOCHS=15000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=3.6389594376681105 



--------
Finished run at 20231111-00:18:21
SQUARED_OUTPUT=True  NUM_EPOCHS=15000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=4.820061615386159 



--------
Finished run at 20231111-00:18:22
SQUARED_OUTPUT=True  NUM_EPOCHS=15000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=3.71860098771651 



--------
Finished run at 20231111-00:18:23
SQUARED_OUTPUT=True  NUM_EPOCHS=15000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=3.033813761472823 



--------
Finished run at 20231111-00:18:25
SQUARED_OUTPUT=True  NUM_EPOCHS=15000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=4.298385423848156 



--------
Finished run at 20231111-00:18:39
SQUARED_OUTPUT=True  NUM_EPOCHS=15000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=3.150582797762488 



--------
Finished run at 20231111-00:18:49
SQUARED_OUTPUT=True  NUM_EPOCHS=15000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=3.15627987669158 



--------
Finished run at 20231111-00:19:06
SQUARED_OUTPUT=True  NUM_EPOCHS=15000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=4.47365090138467 



--------
Finished run at 20231111-00:19:07
SQUARED_OUTPUT=True  NUM_EPOCHS=15000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=2.2856250361146304 



--------
Finished run at 20231111-00:19:08
SQUARED_OUTPUT=True  NUM_EPOCHS=15000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=3.8961745741841876 



--------
Finished run at 20231111-00:19:09
SQUARED_OUTPUT=True  NUM_EPOCHS=15000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=3.1827220795418554 



--------
Finished run at 20231111-00:19:25
SQUARED_OUTPUT=True  NUM_EPOCHS=15000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=3.4067815660603173 



--------
Finished run at 20231111-01:34:04
SQUARED_OUTPUT=True  NUM_EPOCHS=5000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=4.484645626599536 



--------
Finished run at 20231111-01:37:13
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=6.033315337009526e-05 



--------
Finished run at 20231111-01:38:27
SQUARED_OUTPUT=True  NUM_EPOCHS=5000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=5.551624793985444 



--------
Finished run at 20231111-01:42:39
SQUARED_OUTPUT=True  NUM_EPOCHS=15000 DECAY=0.6 final  LEARNING_RATE=0.1 
average_loss_end=4.890701283884828 



--------
Finished run at 20231111-01:43:27
SQUARED_OUTPUT=True  NUM_EPOCHS=35000 DECAY=0.6 final  LEARNING_RATE=0.01 
average_loss_end=3.3048293529880852 



--------
Finished run at 20231111-01:45:38
SQUARED_OUTPUT=True  NUM_EPOCHS=135000 DECAY=0.6 final  LEARNING_RATE=0.01 
average_loss_end=5.661484618827213 



--------
Finished run at 20231111-01:56:39
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=2.645326033468365e-05 



--------
Finished run at 20231111-01:56:41
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=3.7816573143430785e-05 



--------
Finished run at 20231111-01:56:57
SQUARED_OUTPUT=True  NUM_EPOCHS=235000 DECAY=0.6 final  LEARNING_RATE=0.0001 
average_loss_end=4.843835109942748 



--------
Finished run at 20231111-01:57:58
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=6.0182316882332996e-05 



--------
Finished run at 20231111-01:58:08
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=3.656357887871309e-05 



--------
Finished run at 20231111-01:58:15
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=4.00856792166735e-05 



--------
Finished run at 20231111-01:58:48
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=9.379795079195219e-05 



--------
Finished run at 20231111-01:58:55
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=9.853586972917582e-05 



--------
Finished run at 20231111-01:59:11
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=9.218734341877167e-05 



--------
Finished run at 20231111-02:00:11
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=8.46686464630011e-05 



--------
Finished run at 20231111-02:00:14
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=3.889304660100379e-05 



--------
Finished run at 20231111-02:00:21
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=3.4537429543320283e-05 



--------
Finished run at 20231111-02:00:23
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=5.8790062462122705e-05 



--------
Finished run at 20231111-02:00:24
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=4.00371753649722e-05 



--------
Finished run at 20231111-02:00:25
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=1.7758352729998704e-05 



--------
Finished run at 20231111-02:00:41
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=5.608541288771107e-05 



--------
Finished run at 20231111-02:00:43
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=1.678958241859618e-05 



--------
Finished run at 20231111-02:00:45
SQUARED_OUTPUT=True  NUM_EPOCHS=4550000 DECAY=0.6 final  LEARNING_RATE=1.0000000000000002e-06 
average_loss_end=6.583421179223592e-05 



--------
Finished run at 20231111-02:01:50
SQUARED_OUTPUT=True  NUM_EPOCHS=235000 DECAY=0.6 final  LEARNING_RATE=0.01 
average_loss_end=6.7891365823914915 



--------
Finished run at 20231111-02:06:55
 6.3011731912171 average_loss_end
 5000 NUM_EPOCHS
SQUARED_OUTPUT=True  NUM_EPOCHS=5000 DECAY=0.6 . final-LEARNING_RATE=0.01 

--------
Finished run at 2023-11-11-02:53:39
 0.0753182788854208 average_loss_end
 4550000 NUM_EPOCHS
    SQUARED_OUTPUT=True  trying back off learning rate, above was cut at 90% and 95% and 99% of epochs  NUM_EPOCHS=4550000 DECAY=0.6 . final-LEARNING_RATE=0.0002 

--------
Finished run at 2023-11-11-02:53:41
 0.05893418777435375 average_loss_end
 4550000 NUM_EPOCHS
    SQUARED_OUTPUT=True  trying back off learning rate, above was cut at 90% and 95% and 99% of epochs  NUM_EPOCHS=4550000 DECAY=0.6 . final-LEARNING_RATE=0.0002 

--------
Finished run at 2023-11-11-02:53:43
 0.08330519729938181 average_loss_end
 4550000 NUM_EPOCHS
    SQUARED_OUTPUT=True  trying back off learning rate, above was cut at 90% and 95% and 99% of epochs  NUM_EPOCHS=4550000 DECAY=0.6 . final-LEARNING_RATE=0.0002 

--------
Finished run at 2023-11-11-02:54:18
 0.07257430289478999 average_loss_end
 4550000 NUM_EPOCHS
    SQUARED_OUTPUT=True  trying back off learning rate, above was cut at 90% and 95% and 99% of epochs  NUM_EPOCHS=4550000 DECAY=0.6 . final-LEARNING_RATE=0.0002 

--------
Finished run at 2023-11-11-03:31:10
 0.010322877647827454 average_loss_end
 4550000 NUM_EPOCHS
    SQUARED_OUTPUT=True  Learning rate back off BOTH at 90,95,99% and also dynamic if loss is low enough  NUM_EPOCHS=4550000 DECAY=0.6 . final-LEARNING_RATE=8.000000000000002e-09 

--------
Finished run at 2023-11-11-03:31:12
 0.0014663455723982679 average_loss_end
 4550000 NUM_EPOCHS
    SQUARED_OUTPUT=True  Learning rate back off BOTH at 90,95,99% and also dynamic if loss is low enough  NUM_EPOCHS=4550000 DECAY=0.6 . final-LEARNING_RATE=8.000000000000002e-09 

--------
Finished run at 2023-11-11-03:31:46
 0.0021520366378096015 average_loss_end
 4550000 NUM_EPOCHS
    SQUARED_OUTPUT=True  Learning rate back off BOTH at 90,95,99% and also dynamic if loss is low enough  NUM_EPOCHS=4550000 DECAY=0.6 . final-LEARNING_RATE=4.000000000000001e-08 

--------
Finished run at 2023-11-11-03:32:00
 0.0015522241381969479 average_loss_end
 4550000 NUM_EPOCHS
    SQUARED_OUTPUT=True  Learning rate back off BOTH at 90,95,99% and also dynamic if loss is low enough  NUM_EPOCHS=4550000 DECAY=0.6 . final-LEARNING_RATE=8.000000000000002e-09 

--------
Finished run at 2023-11-11-13:04:17
 4.186346901245853 average_loss_end
 5000 NUM_EPOCHS
    SQUARED_OUTPUT=True  Learning rate back off BOTH at 90,95,99% and also dynamic if loss is low enough  NUM_EPOCHS=5000 DECAY=0.6 . final-LEARNING_RATE=1.0000000000000002e-06 

--------
Finished run at 2023-11-11-13:11:23
 4.035860339909989 average_loss_end
 5000 NUM_EPOCHS
    SQUARED_OUTPUT=False    NUM_EPOCHS=5000 DECAY=0.6 ...  final learn: LEARNING_RATE=1.0000000000000002e-06   DYN_LEARNING_RATE=True STEP_LEARN_RATE=True

--------
Finished run at 2023-11-11-13:14:37
 4.010132976980713 average_loss_end
 150000 NUM_EPOCHS
    SQUARED_OUTPUT=False    NUM_EPOCHS=150000 DECAY=0.6 ...  final learn: LEARNING_RATE=0.001   DYN_LEARNING_RATE=True STEP_LEARN_RATE=False

--------
Finished run at 2023-11-11-13:15:00
 3.554410238949966 average_loss_end
 150000 NUM_EPOCHS
    SQUARED_OUTPUT=False    NUM_EPOCHS=150000 DECAY=0.6 ...  final learn: LEARNING_RATE=0.001   DYN_LEARNING_RATE=True STEP_LEARN_RATE=False

--------
Finished run at 2023-11-11-13:15:10
 0.11762288929093177 average_loss_end
 150000 NUM_EPOCHS
    SQUARED_OUTPUT=True    NUM_EPOCHS=150000 DECAY=0.6 ...  final learn: LEARNING_RATE=0.0002   DYN_LEARNING_RATE=True STEP_LEARN_RATE=False

--------
Finished run at 2023-11-11-13:15:12
 0.12309755535840407 average_loss_end
 150000 NUM_EPOCHS
    SQUARED_OUTPUT=True    NUM_EPOCHS=150000 DECAY=0.6 ...  final learn: LEARNING_RATE=0.0002   DYN_LEARNING_RATE=True STEP_LEARN_RATE=False

--------
Finished run at 2023-11-11-16:38:22
 0.003339625283438636 average_loss_end
 2500000 NUM_EPOCHS
    SQUARED_OUTPUT=True    NUM_EPOCHS=2500000 DECAY=0.6 ...  final learn: LEARNING_RATE=4.000000000000001e-08   DYN_LEARNING_RATE=True STEP_LEARN_RATE=True

--------
Finished run at 2023-11-11-16:38:23
 0.002888065732883547 average_loss_end
 2500000 NUM_EPOCHS
    SQUARED_OUTPUT=True    NUM_EPOCHS=2500000 DECAY=0.6 ...  final learn: LEARNING_RATE=4.000000000000001e-08   DYN_LEARNING_RATE=True STEP_LEARN_RATE=True

--------
Finished run at 2023-11-11-16:38:41
 0.0030942852871120295 average_loss_end
 2500000 NUM_EPOCHS
    SQUARED_OUTPUT=True    NUM_EPOCHS=2500000 DECAY=0.6 ...  final learn: LEARNING_RATE=4.000000000000001e-08   DYN_LEARNING_RATE=True STEP_LEARN_RATE=True

--------
Finished run at 2023-11-11-16:40:21
 3.80698459188893 average_loss_end
 2500000 NUM_EPOCHS
    SQUARED_OUTPUT=False    NUM_EPOCHS=2500000 DECAY=0.6 ...  final learn: LEARNING_RATE=2.0000000000000004e-07   DYN_LEARNING_RATE=True STEP_LEARN_RATE=True

--------
Finished run at 2023-11-11-16:40:29
 2.9751969037607076 average_loss_end
 2500000 NUM_EPOCHS
    SQUARED_OUTPUT=False    NUM_EPOCHS=2500000 DECAY=0.6 ...  final learn: LEARNING_RATE=2.0000000000000004e-07   DYN_LEARNING_RATE=True STEP_LEARN_RATE=True

--------
Finished run at 2023-11-11-16:40:32
 2.219408907118301 average_loss_end
 2500000 NUM_EPOCHS
    SQUARED_OUTPUT=False    NUM_EPOCHS=2500000 DECAY=0.6 ...  final learn: LEARNING_RATE=2.0000000000000004e-07   DYN_LEARNING_RATE=True STEP_LEARN_RATE=True

--------
Finished run at 2023-11-11-17:03:15
 0.0001383723486951851 average_loss_end
 2500000 NUM_EPOCHS
    SQUARED_OUTPUT=True    NUM_EPOCHS=2500000 DECAY=0.7 ...  final learn: LEARNING_RATE=1.0000000000000002e-06   DYN_LEARNING_RATE=False STEP_LEARN_RATE=True Step is Learn_rate /10 at 90% 95% and 99%

--------
Finished run at 2023-11-11-17:03:15
 0.0002032109435167797 average_loss_end
 2500000 NUM_EPOCHS
    SQUARED_OUTPUT=True    NUM_EPOCHS=2500000 DECAY=0.7 ...  final learn: LEARNING_RATE=1.0000000000000002e-06   DYN_LEARNING_RATE=False STEP_LEARN_RATE=True Step is Learn_rate /10 at 90% 95% and 99%

--------
Finished run at 2023-11-11-17:15:34
 0.00016223456592877027 average_loss_end
 2500000 NUM_EPOCHS
    SQUARED_OUTPUT=True    NUM_EPOCHS=2500000 DECAY=0.7 ...  final learn: LEARNING_RATE=1.0000000000000002e-06   DYN_LEARNING_RATE=False STEP_LEARN_RATE=True Step is Learn_rate /10 at 90% 95% and 99%
    Added a second hidden layer, so neural net now has 4 total layers 2 hidden are same size as input. Let's see how this does

--------
Finished run at 2023-11-11-17:16:00
 0.00013313826243461336 average_loss_end
 2500000 NUM_EPOCHS
    SQUARED_OUTPUT=True    NUM_EPOCHS=2500000 DECAY=0.7 ...  final learn: LEARNING_RATE=1.0000000000000002e-06   DYN_LEARNING_RATE=False STEP_LEARN_RATE=True Step is Learn_rate /10 at 90% 95% and 99%
    Added a second hidden layer, so neural net now has 4 total layers 2 hidden are same size as input. Let's see how this does